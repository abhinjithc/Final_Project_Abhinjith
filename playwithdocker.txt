Play With Docker
Commands from Console

###############################################################
#                          WARNING!!!!                        #
# This is a sandbox environment. Using personal credentials   #
# is HIGHLY! discouraged. Any consequences of doing so are    #
# completely the user's responsibilites.                      #
#                                                             #
# The PWD team.                                               #
###############################################################
[node1] (local) root@192.168.0.18 ~
$     git clone https://github.com/dockersamples/linux_tweet_app
Cloning into 'linux_tweet_app'...
remote: Enumerating objects: 14, done.
remote: Total 14 (delta 0), reused 0 (delta 0), pack-reused 14
Receiving objects: 100% (14/14), 10.76 KiB | 10.76 MiB/s, done.
Resolving deltas: 100% (5/5), done.
[node1] (local) root@192.168.0.18 ~
$  docker container run alpine hostname
Unable to find image 'alpine:latest' locally
latest: Pulling from library/alpine
59bf1c3509f3: Pull complete
Digest: sha256:21a3deaa0d32a8057914f36584b5288d2e5ecc984380bc0118285c70fa8c9300
Status: Downloaded newer image for alpine:latest
4d7f7887b99d
[node1] (local) root@192.168.0.18 ~
$  docker container ls --all
CONTAINER ID   IMAGE     COMMAND      CREATED         STATUS                    PORTS     NAMES
4d7f7887b99d   alpine    "hostname"   2 seconds ago   Exited (0) 1 second ago         elastic_noether
[node1] (local) root@192.168.0.18 ~
$  docker container run --interactive --tty --rm ubuntu bash
Unable to find image 'ubuntu:latest' locally
latest: Pulling from library/ubuntu
ea362f368469: Pull complete
Digest: sha256:b5a61709a9a44284d88fb12e5c48db0409cfad5b69d4ff8224077c57302df9cf
Status: Downloaded newer image for ubuntu:latest
root@71ed2693110f:/# ls /
bin   dev  home  lib32  libx32  mnt  proc  run   srv  tmp  var
boot  etc  lib   lib64  media   opt  root  sbin  sys  usr
root@71ed2693110f:/# ps aux
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  1.3  0.0   4108  3556 pts/0    Ss   09:37   0:00 bash
root        11  0.0  0.0   5896  2944 pts/0    R+   09:37   0:00 ps aux
root@71ed2693110f:/# cat /etc/issue
Ubuntu 20.04.3 LTS \n \l

root@71ed2693110f:/#  exit
exit
[node1] (local) root@192.168.0.18 ~
$  cat /etc/issue
Welcome to Alpine Linux 3.12
Kernel \r on an \m (\l)

[node1] (local) root@192.168.0.18 ~
$  docker container run \
>  --detach \
>  --name mydb \
>  -e MYSQL_ROOT_PASSWORD=my-secret-pw \
>  mysql:latest
Unable to find image 'mysql:latest' locally
latest: Pulling from library/mysql
72a69066d2fe: Pull complete
93619dbc5b36: Pull complete
99da31dd6142: Pull complete
e5c707858ec0: Pull complete
fc41578cbf60: Pull complete
4785d896ef10: Pull complete
7d250cdc93be: Pull complete
309700f41983: Pull complete
45fd33301836: Pull complete
92f970c68b71: Pull complete
bb3544339a9e: Pull complete
f66ddf4c43fa: Pull complete
Digest: sha256:d0507b008897c39f6cbc76285af1171d4551988475e00e91344060023cd9c553
Status: Downloaded newer image for mysql:latest
c182306c420c60e1a9cdc9d6c254ad5fb853ef5877a685d5f355d6d0aa722851
[node1] (local) root@192.168.0.18 ~
$  docker container ls
CONTAINER ID   IMAGE          COMMAND                  CREATED         STATUS     PORTS                 NAMES
c182306c420c   mysql:latest   "docker-entrypoint.sâ€¦"   5 seconds ago   Up 4 seconds   3306/tcp, 33060/tcp   mydb
[node1] (local) root@192.168.0.18 ~
$  docker container logs mydb
2022-01-20 09:37:52+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 8.0.28-1debian10 started.
2022-01-20 09:37:52+00:00 [Note] [Entrypoint]: Switching to dedicated user 'mysql'
2022-01-20 09:37:52+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 8.0.28-1debian10 started.
2022-01-20 09:37:52+00:00 [Note] [Entrypoint]: Initializing database files
2022-01-20T09:37:52.378291Z 0 [System] [MY-013169] [Server] /usr/sbin/mysqld (mysqld 8.0.28) initializing of server in progress as process 42
2022-01-20T09:37:52.386759Z 1 [System] [MY-013576] [InnoDB] InnoDB initialization has started.
2022-01-20T09:37:52.746366Z 1 [System] [MY-013577] [InnoDB] InnoDB initialization has ended.
2022-01-20T09:37:53.910982Z 6 [Warning] [MY-010453] [Server] root@localhost is created with an empty password ! Please consider switching off the --initialize-insecure option.
2022-01-20 09:37:56+00:00 [Note] [Entrypoint]: Database files initialized
2022-01-20 09:37:56+00:00 [Note] [Entrypoint]: Starting temporary server
2022-01-20T09:37:57.123732Z 0 [System] [MY-010116] [Server] /usr/sbin/mysqld (mysqld 8.0.28) starting as process 91
2022-01-20T09:37:57.143954Z 1 [System] [MY-013576] [InnoDB] InnoDB initialization has started.
2022-01-20T09:37:57.321804Z 1 [System] [MY-013577] [InnoDB] InnoDB initialization has ended.
2022-01-20T09:37:57.596753Z 0 [Warning] [MY-010068] [Server] CA certificate ca.pem is self signed.
2022-01-20T09:37:57.596869Z 0 [System] [MY-013602] [Server] Channel mysql_main configured to support TLS. Encrypted connections are now supported for this channel.
2022-01-20T09:37:57.598415Z 0 [Warning] [MY-011810] [Server] Insecure configuration for --pid-file: Location '/var/run/mysqld' in the path is accessible to all OS users. Consider choosing a different directory.
2022-01-20T09:37:57.628364Z 0 [System] [MY-011323] [Server] X Plugin ready for connections. Socket: /var/run/mysqld/mysqlx.sock
2022-01-20T09:37:57.628950Z 0 [System] [MY-010931] [Server] /usr/sbin/mysqld: ready for connections. Version: '8.0.28'  socket: '/var/run/mysqld/mysqld.sock'  port: 0  MySQL Community Server - GPL.
2022-01-20 09:37:57+00:00 [Note] [Entrypoint]: Temporary server started.
Warning: Unable to load '/usr/share/zoneinfo/iso3166.tab' as time zone. Skippingit.
Warning: Unable to load '/usr/share/zoneinfo/leap-seconds.list' as time zone. Skipping it.
[node1] (local) root@192.168.0.18 ~
$    docker container top mydb
PID                 USER                TIME                COMMAND
1024                999                 0:00                mysqld
[node1] (local) root@192.168.0.18 ~
$  docker exec -it mydb \
>  mysql --user=root --password=$MYSQL_ROOT_PASSWORD --version
mysql: [Warning] Using a password on the command line interface can be insecure.
mysql  Ver 8.0.28 for Linux on x86_64 (MySQL Community Server - GPL)
[node1] (local) root@192.168.0.18 ~
$  docker exec -it mydb sh
#  mysql --user=root --password=$MYSQL_ROOT_PASSWORD --version
mysql: [Warning] Using a password on the command line interface can be insecure.
mysql  Ver 8.0.28 for Linux on x86_64 (MySQL Community Server - GPL)
#  exit
[node1] (local) root@192.168.0.18 ~
$  cd ~/linux_tweet_app
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$  cat Dockerfile
FROM nginx:latest

COPY index.html /usr/share/nginx/html
COPY linux.png /usr/share/nginx/html

EXPOSE 80 443

CMD ["nginx", "-g", "daemon off;"]
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$  docker image build --tag abhinjith/linux_tweet_app:1.0 .
Sending build context to Docker daemon  92.16kB
Step 1/5 : FROM nginx:latest
latest: Pulling from library/nginx
a2abf6c4d29d: Pull complete
a9edb18cadd1: Pull complete
589b7251471a: Pull complete
186b1aaa4aa6: Pull complete
b4df32aa5a72: Pull complete
a0bcbecc962e: Pull complete
Digest: sha256:0d17b565c37bcbd895e9d92315a05c1c3c9a29f762b011a10c54a66cd53c9b31
Status: Downloaded newer image for nginx:latest
 ---> 605c77e624dd
Step 2/5 : COPY index.html /usr/share/nginx/html
 ---> 2f7f9d7e409b
Step 3/5 : COPY linux.png /usr/share/nginx/html
 ---> b4055e7df048
Step 4/5 : EXPOSE 80 443
 ---> Running in 48dcda907203
Removing intermediate container 48dcda907203
 ---> fce9b85c7604
Step 5/5 : CMD ["nginx", "-g", "daemon off;"]
 ---> Running in f80ed15b466a
Removing intermediate container f80ed15b466a
 ---> cbdd6421186f
Successfully built cbdd6421186f
Successfully tagged abhinjith/linux_tweet_app:1.0
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$  docker container run  --detach  --publish 80:80  --name linux_tweet_app  abhinjith/linux_tweet_app:1.0
12876075da87b89e00d02b622b2bab75e997ff57691f02ff570836373886397f
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$  docker container rm --force linux_tweet_app
linux_tweet_app
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$  docker container run  --detach  --publish 80:80  --name linux_tweet_app  --mount type=bind,source="$(pwd)",target=/usr/share/nginx/html  abhinjith/linux_tweet_app:1.0
bbcf874708265c7f889fe35dc266cbced07b76036e2033a6e356b1266351eecd
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$  cp index-new.html index.html
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$  docker rm --force linux_tweet_app
linux_tweet_app
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$  docker container run  --detach  --publish 80:80  --name linux_tweet_app  abhinjith/linux_tweet_app:1.0
8896b9634480481711efb7929e2748bfc450fa74732af1087bc233aaac0e3c1f
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$ docker rm --force linux_tweet_app
linux_tweet_app
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$  docker image build --tag abhinjith/linux_tweet_app:2.0 .
Sending build context to Docker daemon  92.16kB
Step 1/5 : FROM nginx:latest
 ---> 605c77e624dd
Step 2/5 : COPY index.html /usr/share/nginx/html
 ---> 64c8cbe7f240
Step 3/5 : COPY linux.png /usr/share/nginx/html
 ---> 4507c34c0d0f
Step 4/5 : EXPOSE 80 443
 ---> Running in 25d696a0ee8c
Removing intermediate container 25d696a0ee8c
 ---> 06c7c972be3a
Step 5/5 : CMD ["nginx", "-g", "daemon off;"]
 ---> Running in 8341cb544a60
Removing intermediate container 8341cb544a60
 ---> e7991fc8f2f8
Successfully built e7991fc8f2f8
Successfully tagged abhinjith/linux_tweet_app:2.0
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$  docker image ls
REPOSITORY                  TAG       IMAGE ID       CREATED          SIZE
abhinjith/linux_tweet_app   2.0       e7991fc8f2f8   6 seconds ago    142MB
abhinjith/linux_tweet_app   1.0       cbdd6421186f   21 minutes ago   142MB
mysql                       latest    5b4c624c7fe1   5 hours ago      519MB
ubuntu                      latest    d13c942271d6   13 days ago      72.8MB
nginx                       latest    605c77e624dd   3 weeks ago      141MB
alpine                      latest    c059bfaa849c   8 weeks ago      5.59MB
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$  docker container run  --detach  --publish 80:80  --name linux_tweet_app  abhinjith/linux_tweet_app:2.0
435fb557076b4c96fdc39e17ac2469c36eb9db50ff78299b71fb345a1ee5ab71
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$  docker container run  --detach  --publish 8080:80  --name old_linux_tweet_app abhinjith/linux_tweet_app:1.0
b9b67d65144aaac5b18dd6b1d916aa02a9b6130361f33130ac575f1e5d06dd64
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$  docker image ls -f reference="abhinjith/*"
REPOSITORY                  TAG       IMAGE ID       CREATED          SIZE
abhinjith/linux_tweet_app   2.0       e7991fc8f2f8   2 minutes ago    142MB
abhinjith/linux_tweet_app   1.0       cbdd6421186f   24 minutes ago   142MB
[node1] (local) root@192.168.0.18 ~/linux_tweet_app
$



###############################################################
#                          WARNING!!!!                        #
# This is a sandbox environment. Using personal credentials   #
# is HIGHLY! discouraged. Any consequences of doing so are    #
# completely the user's responsibilites.                      #
#                                                             #
# The PWD team.                                               #
###############################################################
[node1] (local) root@192.168.0.18 ~
$ git clone https://github.com/ibnesayeed/linkextractor.git
Cloning into 'linkextractor'...
remote: Enumerating objects: 144, done.
remote: Counting objects: 100% (4/4), done.
remote: Compressing objects: 100% (4/4), done.
remote: Total 144 (delta 0), reused 1 (delta 0), pack-reused 140
Receiving objects: 100% (144/144), 44.55 KiB | 6.36 MiB/s, done.
Resolving deltas: 100% (43/43), done.
[node1] (local) root@192.168.0.18 ~
$ cd linkextractor
[node1] (local) root@192.168.0.18 ~/linkextractor
$ git checkout demo
Branch 'demo' set up to track remote branch 'demo' from 'origin'.
Switched to a new branch 'demo'
[node1] (local) root@192.168.0.18 ~/linkextractor
$ git checkout step0
Branch 'step0' set up to track remote branch 'step0' from 'origin'.
Switched to a new branch 'step0'
[node1] (local) root@192.168.0.18 ~/linkextractor
$ tree
.
â”œâ”€â”€ README.md
â””â”€â”€ linkextractor.py

0 directories, 2 files
[node1] (local) root@192.168.0.18 ~/linkextractor
$ cat linkextractor.py
#!/usr/bin/env python

import sys
import requests
from bs4 import BeautifulSoup

res = requests.get(sys.argv[-1])
soup = BeautifulSoup(res.text, "html.parser")
for link in soup.find_all("a"):
    print(link.get("href"))
[node1] (local) root@192.168.0.18 ~/linkextractor
$ ./linkextractor.py http://example.com/
bash: ./linkextractor.py: Permission denied
[node1] (local) root@192.168.0.18 ~/linkextractor
$ ls -l linkextractor.py
-rw-r--r--    1 root     root           220 Jan 20 10:07 linkextractor.py
[node1] (local) root@192.168.0.18 ~/linkextractor
$ python3 linkextractor.py
Traceback (most recent call last):
  File "linkextractor.py", line 5, in <module>
    from bs4 import BeautifulSoup
ModuleNotFoundError: No module named 'bs4'
[node1] (local) root@192.168.0.18 ~/linkextractor
$ git checkout step1
Branch 'step1' set up to track remote branch 'step1' from 'origin'.
Switched to a new branch 'step1'
[node1] (local) root@192.168.0.18 ~/linkextractor
$ tree
.
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â””â”€â”€ linkextractor.py

0 directories, 3 files
[node1] (local) root@192.168.0.18 ~/linkextractor
$ cat Dockerfile
FROM       python:3
LABEL      maintainer="Sawood Alam <@ibnesayeed>"

RUN        pip install beautifulsoup4
RUN        pip install requests

WORKDIR    /app
COPY       linkextractor.py /app/
RUN        chmod a+x linkextractor.py

ENTRYPOINT ["./linkextractor.py"]
[node1] (local) root@192.168.0.18 ~/linkextractor
$ docker image build -t linkextractor:step1 .
Sending build context to Docker daemon  107.5kB
Step 1/8 : FROM       python:3
3: Pulling from library/python
0e29546d541c: Pull complete
9b829c73b52b: Pull complete
cb5b7ae36172: Pull complete
6494e4811622: Pull complete
6f9f74896dfa: Pull complete
fcb6d5f7c986: Pull complete
3445db4c939c: Pull complete
def920d3ef5d: Pull complete
aabf25a1ee4b: Pull complete
Digest: sha256:a780eec51b47c0684d81315d48524b92e84873f93558f863733333e558d628b6
Status: Downloaded newer image for python:3
 ---> cecf555903c6
Step 2/8 : LABEL      maintainer="Sawood Alam <@ibnesayeed>"
 ---> Running in 705b2ccee317
Removing intermediate container 705b2ccee317
 ---> d372cb580278
Step 3/8 : RUN        pip install beautifulsoup4
 ---> Running in 340043e18d43
Collecting beautifulsoup4
  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)
Collecting soupsieve>1.2
  Downloading soupsieve-2.3.1-py3-none-any.whl (37 kB)
Installing collected packages: soupsieve, beautifulsoup4
Successfully installed beautifulsoup4-4.10.0 soupsieve-2.3.1
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
WARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.
You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.
Removing intermediate container 340043e18d43
 ---> f7374ad153a4
Step 4/8 : RUN        pip install requests
 ---> Running in 9a40bb2f23bd
Collecting requests
  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)
Collecting idna<4,>=2.5
  Downloading idna-3.3-py3-none-any.whl (61 kB)
Collecting charset-normalizer~=2.0.0
  Downloading charset_normalizer-2.0.10-py3-none-any.whl (39 kB)
Collecting certifi>=2017.4.17
  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)
Collecting urllib3<1.27,>=1.21.1
  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)
Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests
Successfully installed certifi-2021.10.8 charset-normalizer-2.0.10 idna-3.3 requests-2.27.1 urllib3-1.26.8
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
WARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.
You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.
Removing intermediate container 9a40bb2f23bd
 ---> 463bc7ddcec1
Step 5/8 : WORKDIR    /app
 ---> Running in deae4fa9abef
Removing intermediate container deae4fa9abef
 ---> 3e44ef752ab4
Step 6/8 : COPY       linkextractor.py /app/
 ---> dfdee8e5cb26
Step 7/8 : RUN        chmod a+x linkextractor.py
 ---> Running in 8e7b6ec22006
Removing intermediate container 8e7b6ec22006
 ---> 80fbe16bc354
Step 8/8 : ENTRYPOINT ["./linkextractor.py"]
 ---> Running in c8ea7d80baf7
Removing intermediate container c8ea7d80baf7
 ---> 14011d568b30
Successfully built 14011d568b30
Successfully tagged linkextractor:step1
[node1] (local) root@192.168.0.18 ~/linkextractor
$ docker image ls
REPOSITORY      TAG       IMAGE ID       CREATED         SIZE
linkextractor   step1     14011d568b30   3 seconds ago   927MB
python          3         cecf555903c6   38 hours ago    917MB
[node1] (local) root@192.168.0.18 ~/linkextractor
$ docker container run -it --rm linkextractor:step1 http://example.com/
https://www.iana.org/domains/example
[node1] (local) root@192.168.0.18 ~/linkextractor
$ docker container run -it --rm linkextractor:step1 https://training.play-with-docker.com/
/
/about/
#ops
#dev
/ops-stage1
/ops-stage2
/ops-stage3
/dev-stage1
/dev-stage2
/dev-stage3
/alacart
https://twitter.com/intent/tweet?text=Play with Docker Classroom&url=https://training.play-with-docker.com/&via=docker&related=docker
https://facebook.com/sharer.php?u=https://training.play-with-docker.com/
https://plus.google.com/share?url=https://training.play-with-docker.com/
http://www.linkedin.com/shareArticle?mini=true&url=https://training.play-with-docker.com/&title=Play%20with%20Docker%20Classroom&source=https://training.play-with-docker.com
https://www.docker.com/dockercon/
https://www.docker.com/dockercon/
https://dockr.ly/slack
https://www.docker.com/legal/docker-terms-service
https://www.docker.com
https://www.facebook.com/docker.run
https://twitter.com/docker
https://www.github.com/play-with-docker/play-with-docker.github.io
[node1] (local) root@192.168.0.18 ~/linkextractor
$
[node1] (local) root@192.168.0.18 ~/linkextractor
$ git checkout step3
Branch 'step3' set up to track remote branch 'step3' from 'origin'.
Switched to a new branch 'step3'
[node1] (local) root@192.168.0.18 ~/linkextractor
$ tree
.
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â”œâ”€â”€ linkextractor.py
â”œâ”€â”€ main.py
â””â”€â”€ requirements.txt

0 directories, 5 files
[node1] (local) root@192.168.0.18 ~/linkextractor
$ cat Dockerfile
FROM       python:3
LABEL      maintainer="Sawood Alam <@ibnesayeed>"

WORKDIR    /app
COPY       requirements.txt /app/
RUN        pip install -r requirements.txt

COPY       *.py /app/
RUN        chmod a+x *.py

CMD        ["./main.py"]
[node1] (local) root@192.168.0.18 ~/linkextractor
$ cat main.py
#!/usr/bin/env python

from flask import Flask
from flask import request
from flask import jsonify
from linkextractor import extract_links

app = Flask(__name__)

@app.route("/")
def index():
    return "Usage: http://<hostname>[:<prt>]/api/<url>"

@app.route("/api/<path:url>")
def api(url):
    qs = request.query_string.decode("utf-8")
    if qs != "":
        url += "?" + qs
    links = extract_links(url)
    return jsonify(links)

app.run(host="0.0.0.0")
[node1] (local) root@192.168.0.18 ~/linkextractor
$ docker image build -t linkextractor:step3 .
Sending build context to Docker daemon  115.2kB
Step 1/8 : FROM       python:3
 ---> cecf555903c6
Step 2/8 : LABEL      maintainer="Sawood Alam <@ibnesayeed>"
 ---> Using cache
 ---> d372cb580278
Step 3/8 : WORKDIR    /app
 ---> Running in a88ae39f236b
Removing intermediate container a88ae39f236b
 ---> c96f7bf76249
Step 4/8 : COPY       requirements.txt /app/
 ---> 236f935967e8
Step 5/8 : RUN        pip install -r requirements.txt
 ---> Running in b953f3280399
Collecting beautifulsoup4
  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)
Collecting flask
  Downloading Flask-2.0.2-py3-none-any.whl (95 kB)
Collecting requests
  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)
Collecting soupsieve>1.2
  Downloading soupsieve-2.3.1-py3-none-any.whl (37 kB)
Collecting Jinja2>=3.0
  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)
Collecting Werkzeug>=2.0
  Downloading Werkzeug-2.0.2-py3-none-any.whl (288 kB)
Collecting click>=7.1.2
  Downloading click-8.0.3-py3-none-any.whl (97 kB)
Collecting itsdangerous>=2.0
  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)
Collecting urllib3<1.27,>=1.21.1
  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)
Collecting charset-normalizer~=2.0.0
  Downloading charset_normalizer-2.0.10-py3-none-any.whl (39 kB)
Collecting idna<4,>=2.5
  Downloading idna-3.3-py3-none-any.whl (61 kB)
Collecting certifi>=2017.4.17
  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)
Collecting MarkupSafe>=2.0
  Downloading MarkupSafe-2.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)
Installing collected packages: MarkupSafe, Werkzeug, urllib3, soupsieve, Jinja2,itsdangerous, idna, click, charset-normalizer, certifi, requests, flask, beautifulsoup4
Successfully installed Jinja2-3.0.3 MarkupSafe-2.0.1 Werkzeug-2.0.2 beautifulsoup4-4.10.0 certifi-2021.10.8 charset-normalizer-2.0.10 click-8.0.3 flask-2.0.2 idna-3.3 itsdangerous-2.0.1 requests-2.27.1 soupsieve-2.3.1 urllib3-1.26.8
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
WARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.
You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.
Removing intermediate container b953f3280399
 ---> c51a576aa41a
Step 6/8 : COPY       *.py /app/
 ---> d9151b07d42d
Step 7/8 : RUN        chmod a+x *.py
 ---> Running in 4c6e26e560fe
Removing intermediate container 4c6e26e560fe
 ---> fd75695c29b0
Step 8/8 : CMD        ["./main.py"]
 ---> Running in 4bd1ea07bf3b
Removing intermediate container 4bd1ea07bf3b
 ---> 3d4c8b7ee115
Successfully built 3d4c8b7ee115
Successfully tagged linkextractor:step3
[node1] (local) root@192.168.0.18 ~/linkextractor
$ docker container run -d -p 5000:5000 --name=linkextractor linkextractor:step3
3a2d01a8dd8d156f98cf9b6327e4b3d69cdc6eaf1392c48402972352d88cbedc
[node1] (local) root@192.168.0.18 ~/linkextractor
$ docker container ls
CONTAINER ID   IMAGE                 COMMAND       CREATED          STATUS   PORTS                    NAMES
3a2d01a8dd8d   linkextractor:step3   "./main.py"   13 seconds ago   Up 13 seconds   0.0.0.0:5000->5000/tcp   linkextractor
[node1] (local) root@192.168.0.18 ~/linkextractor
$ curl -i http://localhost:5000/api/http://example.com/
HTTP/1.0 200 OK
Content-Type: application/json
Content-Length: 79
Server: Werkzeug/2.0.2 Python/3.10.2
Date: Thu, 20 Jan 2022 10:10:26 GMT

[{"href":"https://www.iana.org/domains/example","text":"More information..."}]
[node1] (local) root@192.168.0.18 ~/linkextractor
$ docker container logs linkextractor
 * Serving Flask app 'main' (lazy loading)
 * Environment: production
   WARNING: This is a development server. Do not use it in a production deployment.
   Use a production WSGI server instead.
 * Debug mode: off
 * Running on all addresses.
   WARNING: This is a development server. Do not use it in a production deployment.
 * Running on http://172.17.0.2:5000/ (Press CTRL+C to quit)
172.17.0.1 - - [20/Jan/2022 10:10:26] "GET /api/http://example.com/ HTTP/1.1" 200 -
[node1] (local) root@192.168.0.18 ~/linkextractor
$ docker container rm -f linkextractor
linkextractor
[node1] (local) root@192.168.0.18 ~/linkextractor
$

[node1] (local) root@192.168.0.18 ~/linkextractor
$ git checkout step4
Branch 'step4' set up to track remote branch 'step4' from 'origin'.
Switched to a new branch 'step4'
[node1] (local) root@192.168.0.18 ~/linkextractor
$ tree
.
â”œâ”€â”€ README.md
â”œâ”€â”€ api
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ linkextractor.py
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ www
    â””â”€â”€ index.php

2 directories, 7 files
[node1] (local) root@192.168.0.18 ~/linkextractor
$ cat docker-compose.yml
version: '3'

services:
  api:
    image: linkextractor-api:step4-python
    build: ./api
    ports:
      - "5000:5000"
  web:
    image: php:7-apache
    ports:
      - "80:80"
    environment:
      - API_ENDPOINT=http://api:5000/api/
    volumes:
      - ./www:/var/www/html
[node1] (local) root@192.168.0.18 ~/linkextractor
$ cat www/index.php
<!DOCTYPE html>

<?php
  $api_endpoint = $_ENV["API_ENDPOINT"] ?: "http://localhost:5000/api/";
  $url = "";
  if(isset($_GET["url"]) && $_GET["url"] != "") {
    $url = $_GET["url"];
    $json = @file_get_contents($api_endpoint . $url);
    if($json == false) {
      $err = "Something is wrong with the URL: " . $url;
    } else {
      $links = json_decode($json, true);
      $domains = [];
      foreach($links as $link) {
        array_push($domains, parse_url($link["href"], PHP_URL_HOST));
      }
      $domainct = @array_count_values($domains);
      arsort($domainct);
    }
  }
?>

<html>
  <head>
    <meta charset="utf-8">
    <title>Link Extractor</title>
    <style media="screen">
      html {
        background: #EAE7D6;
        font-family: sans-serif;
      }
      body {
        margin: 0;
      }
      h1 {
        padding: 10px;
        margin: 0 auto;
        color: #EAE7D6;
        max-width: 600px;
      }
      h1 a {
        text-decoration: none;
        color: #EAE7D6;
      }
      h2 {
        background: #082E41;
        color: #EAE7D6;
        margin: -10px;
        padding: 10px;
      }
      p {
        margin: 25px 5px 5px;
      }
      section {
        max-width: 600px;
        margin: 10px auto;
        padding: 10px;
        border: 1px solid #082E41;
      }
      div.header {
        background: #082E41;
        margin: 0;
      }
      div.footer {
        background: #082E41;
        margin: 0;
        padding: 5px;
      }
      .footer p {
        margin: 0 auto;
        max-width: 600px;
        color: #EAE7D6;
        text-align: center;
      }
      .footer p a {
        color: #24C2CB;
        text-decoration: none;
      }
      .error {
        color: #DA2536;
      }
      form {
        display: flex;
      }
      input {
        font-size: 20px;
        padding: 3px;
        height: 40px;
      }
      input.text {
        box-sizing:border-box;
        flex-grow: 1;
        border-color: #082E41;
      }
      input.button {
        width: 150px;
        background: #082E41;
        border-color: #082E41;
        color: #EAE7D6;
      }
      table {
        width: 100%;
        text-align: left;
        margin-top: 10px;
      }
      table th, table td {
        padding: 3px;
      }
      table th:last-child, table td:last-child {
        width: 70px;
        text-align: right;
      }
      table th {
        border-top: 1px solid #082E41;
        border-bottom: 1px solid #082E41;
      }
      table tr:last-child td {
        border-top: 1px solid #082E41;
        border-bottom: 1px solid #082E41;
      }
    </style>
  </head>
  <body>
    <div class="header">
      <h1><a href="/">Link Extractor</a></h1>
    </div>

    <section>
      <form action="/">
        <input class="text" type="text" name="url" placeholder="http://example.com/" value="<?php echo $url; ?>">
        <input class="button" type="submit" value="Extract Links">
      </form>
    </section>

    <?php if(isset($err)): ?>
      <section>
        <h2>Error</h2>
        <p class="error"><?php echo $err; ?></p>
      </section>
    <?php endif; ?>

    <?php if($url != "" && !isset($err)): ?>
      <section>
        <h2>Summary</h2>
        <p>
          <strong>Page:</strong> <?php echo "<a href=\"" . $url . "\">" . $url ."</a>"; ?>
        </p>
        <table>
          <tr>
            <th>Domain</th>
            <th># Links</th>
          </tr>
          <?php
            foreach($domainct as $key => $value) {
              echo "<tr>";
              echo "<td>" . $key . "</td>";
              echo "<td>" . $value . "</td>";
              echo "</tr>";
            }
          ?>
          <tr>
            <td><strong>Total</strong></td>
            <td><strong><?php echo count($links); ?></strong></td>
          </tr>
        </table>
      </section>

      <section>
        <h2>Links</h2>
        <ul>
        <?php
          foreach($links as $link) {
            echo "<li><a href=\"" . $link["href"] . "\">" . $link["text"] . "</a></li>";
          }
        ?>
        </ul>
      </section>
    <?php endif; ?>

    <div class="footer">
      <p><a href="https://github.com/ibnesayeed/linkextractor">Link Extractor</a> by <a href="https://twitter.com/ibnesayeed">@ibnesayeed</a> from
        <a href="https://ws-dl.cs.odu.edu/">WS-DL, ODU</a>
      </p>
    </div>
  </body>
</html>
[node1] (local) root@192.168.0.18 ~/linkextractor
$ docker-compose up -d --build
Creating network "linkextractor_default" with the default driver
Building api
Step 1/8 : FROM       python:3
 ---> cecf555903c6
Step 2/8 : LABEL      maintainer="Sawood Alam <@ibnesayeed>"
 ---> Using cache
 ---> d372cb580278
Step 3/8 : WORKDIR    /app
 ---> Using cache
 ---> c96f7bf76249
Step 4/8 : COPY       requirements.txt /app/
 ---> b968517c3fe6
Step 5/8 : RUN        pip install -r requirements.txt
 ---> Running in 8c208a0b60cb
Collecting beautifulsoup4
  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)
Collecting flask
  Downloading Flask-2.0.2-py3-none-any.whl (95 kB)
Collecting requests
  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)
Collecting soupsieve>1.2
  Downloading soupsieve-2.3.1-py3-none-any.whl (37 kB)
Collecting click>=7.1.2
  Downloading click-8.0.3-py3-none-any.whl (97 kB)
Collecting Jinja2>=3.0
  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)
Collecting itsdangerous>=2.0
  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)
Collecting Werkzeug>=2.0
  Downloading Werkzeug-2.0.2-py3-none-any.whl (288 kB)
Collecting urllib3<1.27,>=1.21.1
  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)
Collecting certifi>=2017.4.17
  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)
Collecting idna<4,>=2.5
  Downloading idna-3.3-py3-none-any.whl (61 kB)
Collecting charset-normalizer~=2.0.0
  Downloading charset_normalizer-2.0.10-py3-none-any.whl (39 kB)
Collecting MarkupSafe>=2.0
  Downloading MarkupSafe-2.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)
Installing collected packages: MarkupSafe, Werkzeug, urllib3, soupsieve, Jinja2,itsdangerous, idna, click, charset-normalizer, certifi, requests, flask, beautifulsoup4
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
Successfully installed Jinja2-3.0.3 MarkupSafe-2.0.1 Werkzeug-2.0.2 beautifulsoup4-4.10.0 certifi-2021.10.8 charset-normalizer-2.0.10 click-8.0.3 flask-2.0.2 idna-3.3 itsdangerous-2.0.1 requests-2.27.1 soupsieve-2.3.1 urllib3-1.26.8
WARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.
You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.
Removing intermediate container 8c208a0b60cb
 ---> db911617cdf1
Step 6/8 : COPY       *.py /app/
 ---> 09c86c7088b1
Step 7/8 : RUN        chmod a+x *.py
 ---> Running in 1c79683551ea
Removing intermediate container 1c79683551ea
 ---> 9d829cabe89f
Step 8/8 : CMD        ["./main.py"]
 ---> Running in 514eccaa72d5
Removing intermediate container 514eccaa72d5
 ---> bbb696546b40
Successfully built bbb696546b40
Successfully tagged linkextractor-api:step4-python
Pulling web (php:7-apache)...
7-apache: Pulling from library/php
a2abf6c4d29d: Pull complete
c5608244554d: Pull complete
2d07066487a0: Pull complete
1b6dfaf1958c: Pull complete
32c5e6a60073: Pull complete
90cf855b27cc: Pull complete
8b0f1068c586: Pull complete
5355461305e8: Pull complete
ad1eec592342: Pull complete
e03fbc76cb78: Pull complete
1f5796e48b39: Pull complete
72fbe8e1d4e7: Pull complete
96edece66175: Pull complete
Digest: sha256:729ad01c7d8e10fd992a6d4f3eb05dce3fb69bdf5c4fb4a9de4be4f4f5ae4dcc
Status: Downloaded newer image for php:7-apache
Creating linkextractor_web_1 ... done
Creating linkextractor_api_1 ... done
[node1] (local) root@192.168.0.18 ~/linkextractor
$ docker container ls
CONTAINER ID   IMAGE                            COMMAND                  CREATED         STATUS          PORTS                    NAMES
28cab87f14a9   linkextractor-api:step4-python   "./main.py"              11 seconds ago   Up 10 seconds   0.0.0.0:5000->5000/tcp   linkextractor_api_1
f7bda4355b11   php:7-apache                     "docker-php-entrypoiâ€¦"   11 seconds ago   Up 10 seconds   0.0.0.0:80->80/tcp       linkextractor_web_1
[node1] (local) root@192.168.0.18 ~/linkextractor
$ curl -i http://localhost:5000/api/http://example.com/
HTTP/1.0 200 OK
Content-Type: application/json
Content-Length: 79
Server: Werkzeug/2.0.2 Python/3.10.2
Date: Thu, 20 Jan 2022 10:12:10 GMT

[{"href":"https://www.iana.org/domains/example","text":"More information..."}]
[node1] (local) root@192.168.0.18 ~/linkextractor
$ sed -i 's/Link Extractor/Super Link Extractor/g' www/index.php
[node1] (local) root@192.168.0.18 ~/linkextractor
$ git reset --hard
HEAD is now at 2a3ec3e Synchronize branch step4
[node1] (local) root@192.168.0.18 ~/linkextractor
$ docker-compose down
Stopping linkextractor_api_1 ... done
Stopping linkextractor_web_1 ... done
Removing linkextractor_api_1 ... done
Removing linkextractor_web_1 ... done
Removing network linkextractor_default
[node1] (local) root@192.168.0.18 ~/linkextractor
$

[node1] (local) root@192.168.0.18 ~/linkextractor
$ git checkout step5
Branch 'step5' set up to track remote branch 'step5' from 'origin'.
Switched to a new branch 'step5'
[node1] (local) root@192.168.0.18 ~/linkextractor
$ tree
.
â”œâ”€â”€ README.md
â”œâ”€â”€ api
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ linkextractor.py
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ www
    â”œâ”€â”€ Dockerfile
    â””â”€â”€ index.php

2 directories, 8 files
[node1] (local) root@192.168.0.18 ~/linkextractor
$ cat www/Dockerfile
FROM       php:7-apache
LABEL      maintainer="Sawood Alam <@ibnesayeed>"

ENV        API_ENDPOINT="http://localhost:5000/api/"

COPY       . /var/www/html/
[node1] (local) root@192.168.0.18 ~/linkextractor
$ cat api/main.py
#!/usr/bin/env python

import os
import json
import redis
from flask import Flask
from flask import request
from linkextractor import extract_links

app = Flask(__name__)
redis_conn = redis.from_url(os.getenv("REDIS_URL", "redis://localhost:6379"))

@app.route("/")
def index():
    return "Usage: http://<hostname>[:<prt>]/api/<url>"

@app.route("/api/<path:url>")
def api(url):
    qs = request.query_string.decode("utf-8")
    if qs != "":
        url += "?" + qs

    jsonlinks = redis_conn.get(url)
    if not jsonlinks:
        links = extract_links(url)
        jsonlinks = json.dumps(links, indent=2)
        redis_conn.set(url, jsonlinks)

    response = app.response_class(
        status=200,
        mimetype="application/json",
        response=jsonlinks
    )

    return response

app.run(host="0.0.0.0")
[node1] (local) root@192.168.0.18 ~/linkextractor
$ cat docker-compose.yml
version: '3'

services:
  api:
    image: linkextractor-api:step5-python
    build: ./api
    ports:
      - "5000:5000"
    environment:
      - REDIS_URL=redis://redis:6379
  web:
    image: linkextractor-web:step5-php
    build: ./www
    ports:
      - "80:80"
    environment:
      - API_ENDPOINT=http://api:5000/api/
  redis:
    image: redis
[node1] (local) root@192.168.0.18 ~/linkextractor
$ docker-compose up -d --build
Creating network "linkextractor_default" with the default driver
Building api
Step 1/9 : FROM       python:3
 ---> cecf555903c6
Step 2/9 : LABEL      maintainer="Sawood Alam <@ibnesayeed>"
 ---> Using cache
 ---> d372cb580278
Step 3/9 : ENV        REDIS_URL="redis://localhost:6379"
 ---> Running in a3deeedc107b
Removing intermediate container a3deeedc107b
 ---> 2025f255351a
Step 4/9 : WORKDIR    /app
 ---> Running in 5a4c01379f44
Removing intermediate container 5a4c01379f44
 ---> 846b0d526bb9
Step 5/9 : COPY       requirements.txt /app/
 ---> 951da0aaf0b2
Step 6/9 : RUN        pip install -r requirements.txt
 ---> Running in 85798471693b
Collecting beautifulsoup4
  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)
Collecting flask
  Downloading Flask-2.0.2-py3-none-any.whl (95 kB)
Collecting redis
  Downloading redis-4.1.1-py3-none-any.whl (173 kB)
Collecting requests
  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)
Collecting soupsieve>1.2
  Downloading soupsieve-2.3.1-py3-none-any.whl (37 kB)
Collecting Werkzeug>=2.0
  Downloading Werkzeug-2.0.2-py3-none-any.whl (288 kB)
Collecting itsdangerous>=2.0
  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)
Collecting Jinja2>=3.0
  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)
Collecting click>=7.1.2
  Downloading click-8.0.3-py3-none-any.whl (97 kB)
Collecting packaging>=20.4
  Downloading packaging-21.3-py3-none-any.whl (40 kB)
Collecting deprecated>=1.2.3
  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)
Collecting idna<4,>=2.5
  Downloading idna-3.3-py3-none-any.whl (61 kB)
Collecting charset-normalizer~=2.0.0
  Downloading charset_normalizer-2.0.10-py3-none-any.whl (39 kB)
Collecting certifi>=2017.4.17
  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)
Collecting urllib3<1.27,>=1.21.1
  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)
Collecting wrapt<2,>=1.10
  Downloading wrapt-1.13.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (81 kB)
Collecting MarkupSafe>=2.0
  Downloading MarkupSafe-2.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)
Collecting pyparsing!=3.0.5,>=2.0.2
  Downloading pyparsing-3.0.6-py3-none-any.whl (97 kB)
Installing collected packages: wrapt, pyparsing, MarkupSafe, Werkzeug, urllib3, soupsieve, packaging, Jinja2, itsdangerous, idna, deprecated, click, charset-normalizer, certifi, requests, redis, flask, beautifulsoup4
Successfully installed Jinja2-3.0.3 MarkupSafe-2.0.1 Werkzeug-2.0.2 beautifulsoup4-4.10.0 certifi-2021.10.8 charset-normalizer-2.0.10 click-8.0.3 deprecated-1.2.13 flask-2.0.2 idna-3.3 itsdangerous-2.0.1 packaging-21.3 pyparsing-3.0.6 redis-4.1.1 requests-2.27.1 soupsieve-2.3.1 urllib3-1.26.8 wrapt-1.13.3
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
WARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.
You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.
Removing intermediate container 85798471693b
 ---> 3055a67aea9c
Step 7/9 : COPY       *.py /app/
 ---> df9cff9fcf3a
Step 8/9 : RUN        chmod a+x *.py
 ---> Running in bb2302e4f691
Removing intermediate container bb2302e4f691
 ---> 38b01fc12811
Step 9/9 : CMD        ["./main.py"]
 ---> Running in 8e555a910677
Removing intermediate container 8e555a910677
 ---> 1c54b8f0a93d
Successfully built 1c54b8f0a93d
Successfully tagged linkextractor-api:step5-python
Building web
Step 1/4 : FROM       php:7-apache
 ---> 0a4f19d60710
Step 2/4 : LABEL      maintainer="Sawood Alam <@ibnesayeed>"
 ---> Running in 6abc11c69f15
Removing intermediate container 6abc11c69f15
 ---> 3d54d487dbc8
Step 3/4 : ENV        API_ENDPOINT="http://localhost:5000/api/"
 ---> Running in 6a66b76fb989
Removing intermediate container 6a66b76fb989
 ---> c48a1f723b81
Step 4/4 : COPY       . /var/www/html/
 ---> 19d9ea6daae6
Successfully built 19d9ea6daae6
Successfully tagged linkextractor-web:step5-php
Pulling redis (redis:)...
latest: Pulling from library/redis
a2abf6c4d29d: Already exists
c7a4e4382001: Pull complete
4044b9ba67c9: Pull complete
c8388a79482f: Pull complete
413c8bb60be2: Pull complete
1abfd3011519: Pull complete
Digest: sha256:db485f2e245b5b3329fdc7eff4eb00f913e09d8feb9ca720788059fdc2ed8339
Status: Downloaded newer image for redis:latest
Creating linkextractor_api_1   ... done
Creating linkextractor_web_1   ... done
Creating linkextractor_redis_1 ... done
[node1] (local) root@192.168.0.18 ~/linkextractor
$ docker-compose exec redis redis-cli monitor
OK
^C[node1] (local) root@192.168.0.18 ~/linkextractor
$
[node1] (local) root@192.168.0.18 ~/linkextractor
$ sed -i 's/Link Extractor/Super Link Extractor/g' www/index.php
[node1] (local) root@192.168.0.18 ~/linkextractor
$ git reset --hard
HEAD is now at 3dbb7eb Synchronize branch step5
[node1] (local) root@192.168.0.18 ~/linkextractor
$ docker-compose down
Stopping linkextractor_redis_1 ... done
Stopping linkextractor_web_1   ... done
Stopping linkextractor_api_1   ... done
Removing linkextractor_redis_1 ... done
Removing linkextractor_web_1   ... done
Removing linkextractor_api_1   ... done
Removing network linkextractor_default
[node1] (local) root@192.168.0.18 ~/linkextractor
$

[node1] (local) root@192.168.0.18 ~/linkextractor
$
[node1] (local) root@192.168.0.18 ~/linkextractor
$ git checkout step6
Branch 'step6' set up to track remote branch 'step6' from 'origin'.
Switched to a new branch 'step6'
[node1] (local) root@192.168.0.18 ~/linkextractor
$ tree
.
â”œâ”€â”€ README.md
â”œâ”€â”€ api
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ Gemfile
â”‚   â””â”€â”€ linkextractor.rb
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ logs
â””â”€â”€ www
    â”œâ”€â”€ Dockerfile
    â””â”€â”€ index.php

3 directories, 7 files
[node1] (local) root@192.168.0.18 ~/linkextractor
$ cat api/linkextractor.rb
#!/usr/bin/env ruby
# encoding: utf-8

require "sinatra"
require "open-uri"
require "uri"
require "nokogiri"
require "json"
require "redis"

set :protection, :except=>:path_traversal

redis = Redis.new(url: ENV["REDIS_URL"] || "redis://localhost:6379")

Dir.mkdir("logs") unless Dir.exist?("logs")
cache_log = File.new("logs/extraction.log", "a")

get "/" do
  "Usage: http://<hostname>[:<prt>]/api/<url>"
end

get "/api/*" do
  url = [params['splat'].first, request.query_string].reject(&:empty?).join("?")
  cache_status = "HIT"
  jsonlinks = redis.get(url)
  if jsonlinks.nil?
    cache_status = "MISS"
    jsonlinks = JSON.pretty_generate(extract_links(url))
    redis.set(url, jsonlinks)
  end

  cache_log.puts "#{Time.now.to_i}\t#{cache_status}\t#{url}"

  status 200
  headers "content-type" => "application/json"
  body jsonlinks
end

def extract_links(url)
  links = []
  doc = Nokogiri::HTML(open(url))
  doc.css("a").each do |link|
    text = link.text.strip.split.join(" ")
    begin
      links.push({
        text: text.empty? ? "[IMG]" : text,
        href: URI.join(url, link["href"])
      })
    rescue
    end
  end
  links
end
[node1] (local) root@192.168.0.18 ~/linkextractor
$ cat api/Dockerfile
FROM       ruby:2.6
LABEL      maintainer="Sawood Alam <@ibnesayeed>"

ENV        LANG C.UTF-8
ENV        REDIS_URL="redis://localhost:6379"

WORKDIR    /app
COPY       Gemfile /app/
RUN        bundle install

COPY       linkextractor.rb /app/
RUN        chmod a+x linkextractor.rb

CMD        ["./linkextractor.rb", "-o", "0.0.0.0"]
[node1] (local) root@192.168.0.18 ~/linkextractor
$ cat docker-compose.yml
version: '3'

services:
  api:
    image: linkextractor-api:step6-ruby
    build: ./api
    ports:
      - "4567:4567"
    environment:
      - REDIS_URL=redis://redis:6379
    volumes:
      - ./logs:/app/logs
  web:
    image: linkextractor-web:step6-php
    build: ./www
    ports:
      - "80:80"
    environment:
      - API_ENDPOINT=http://api:4567/api/
  redis:
    image: redis
[node1] (local) root@192.168.0.18 ~/linkextractor
$ docker-compose up -d --build
Creating network "linkextractor_default" with the default driver
Building api
Step 1/10 : FROM       ruby:2.6
2.6: Pulling from library/ruby
0e29546d541c: Already exists
9b829c73b52b: Already exists
cb5b7ae36172: Already exists
6494e4811622: Already exists
6f9f74896dfa: Already exists
8692434624fe: Pull complete
9ffb5805107e: Pull complete
be7151ad9312: Pull complete
Digest: sha256:634a743c2cb4b51cc9d887103c383e70aef4040b0540fa295d7aed9659320c6d
Status: Downloaded newer image for ruby:2.6
 ---> 9a2d45e2219e
Step 2/10 : LABEL      maintainer="Sawood Alam <@ibnesayeed>"
 ---> Running in e5bac2156db7
Removing intermediate container e5bac2156db7
 ---> fb4c0b1e9031
Step 3/10 : ENV        LANG C.UTF-8
 ---> Running in 347a8e3fee0e
Removing intermediate container 347a8e3fee0e
 ---> 09847d1f4d40
Step 4/10 : ENV        REDIS_URL="redis://localhost:6379"
 ---> Running in 1d9a1fef470e
Removing intermediate container 1d9a1fef470e
 ---> 92f43264e322
Step 5/10 : WORKDIR    /app
 ---> Running in 50a99a383675
Removing intermediate container 50a99a383675
 ---> 0f8d0b2c5e3e
Step 6/10 : COPY       Gemfile /app/
 ---> b4d700cf835a
Step 7/10 : RUN        bundle install
 ---> Running in 94cae8533761
Fetching gem metadata from https://rubygems.org/.......
Resolving dependencies...
Using bundler 1.17.2
Fetching mini_portile2 2.7.1
Installing mini_portile2 2.7.1
Fetching ruby2_keywords 0.0.5
Installing ruby2_keywords 0.0.5
Fetching mustermann 1.1.1
Installing mustermann 1.1.1
Fetching racc 1.6.0
Installing racc 1.6.0 with native extensions
Fetching nokogiri 1.13.1 (x86_64-linux)
Installing nokogiri 1.13.1 (x86_64-linux)
Fetching rack 2.2.3
Installing rack 2.2.3
Fetching rack-protection 2.1.0
Installing rack-protection 2.1.0
Fetching redis 4.5.1
Installing redis 4.5.1
Fetching tilt 2.0.10
Installing tilt 2.0.10
Fetching sinatra 2.1.0
Installing sinatra 2.1.0
Bundle complete! 3 Gemfile dependencies, 11 gems now installed.
Use `bundle info [gemname]` to see where a bundled gem is installed.
Removing intermediate container 94cae8533761
 ---> bda9a0820f25
Step 8/10 : COPY       linkextractor.rb /app/
 ---> 9e85d5f368d1
Step 9/10 : RUN        chmod a+x linkextractor.rb
 ---> Running in ce3827d82f82
Removing intermediate container ce3827d82f82
 ---> 24af370b5a29
Step 10/10 : CMD        ["./linkextractor.rb", "-o", "0.0.0.0"]
 ---> Running in 66c18bc12f64
Removing intermediate container 66c18bc12f64
 ---> 0f36a82d2c10
Successfully built 0f36a82d2c10
Successfully tagged linkextractor-api:step6-ruby
Building web
Step 1/3 : FROM       php:7-apache
 ---> 0a4f19d60710
Step 2/3 : LABEL      maintainer="Sawood Alam <@ibnesayeed>"
 ---> Using cache
 ---> 0ea1ee7d2913
Step 3/3 : COPY       . /var/www/html/
 ---> 2b65b06b31e5
Successfully built 2b65b06b31e5
Successfully tagged linkextractor-web:step6-php
Creating linkextractor_api_1   ... done
Creating linkextractor_web_1   ... done
Creating linkextractor_redis_1 ... done
[node1] (local) root@192.168.0.18 ~/linkextractor
$ curl -i http://localhost:4567/api/http://example.com/
HTTP/1.1 200 OK
Content-Type: application/json
Content-Length: 97
X-Content-Type-Options: nosniff
Server: WEBrick/1.4.4 (Ruby/2.6.9/2021-11-24)
Date: Thu, 20 Jan 2022 10:35:21 GMT
Connection: Keep-Alive

[
  {
    "text": "More information...",
    "href": "https://www.iana.org/domains/example"
  }
][node1] (local) root@192.168.0.18 ~/linkextractor
$
[node1] (local) root@192.168.0.18 ~/linkextractor
$ docker-compose down
Stopping linkextractor_redis_1 ... done
Stopping linkextractor_web_1   ... done
Stopping linkextractor_api_1   ... done
Removing linkextractor_redis_1 ... done
Removing linkextractor_web_1   ... done
Removing linkextractor_api_1   ... done
Removing network linkextractor_default
[node1] (local) root@192.168.0.18 ~/linkextractor
$
